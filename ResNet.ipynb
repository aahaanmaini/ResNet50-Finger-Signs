{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3UgFU3RRZsR"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import function\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import *\n",
        "from keras.initializers import glorot_uniform\n",
        "from matplotlib.pyplot import imshow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdnoLsNbW3_A"
      },
      "source": [
        "def bn_relu(X, axis, activation):\n",
        "  X_out = BatchNormalization(axis=axis)(X)\n",
        "  X_out = Activation(activation)(X_out)\n",
        "\n",
        "  return X_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJdHlNEgSzEN"
      },
      "source": [
        "def res_block(X, f, filters):\n",
        "  F1, F2, F3 = filters\n",
        "  X_skipped = X\n",
        "\n",
        "  #Layer 1\n",
        "  X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1,1), padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = bn_relu(X, 3, \"relu\")\n",
        "\n",
        "  #Layer 2\n",
        "  X = Conv2D(filters=F2, kernel_size=(f,f), strides=(1,1), padding=\"same\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "  X = bn_relu(X, 3, \"relu\")\n",
        "\n",
        "  #Layer 3\n",
        "  X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding=\"valid\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "  X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "  X = Add()([X, X_skipped])\n",
        "  X = Activation(\"relu\")(X)\n",
        "\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSMKGkDjbc8w"
      },
      "source": [
        "def conv_block(X, f, s, filters):\n",
        "  F1, F2, F3 = filters\n",
        "  x_short_orig = X\n",
        "\n",
        "  #Layer 1\n",
        "  X = Conv2D(filters=F1, kernel_size=(1,1), strides=(s,s), padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = bn_relu(X, 3, \"relu\")\n",
        "\n",
        "  #Layer 2\n",
        "  X = Conv2D(filters=F2, kernel_size=(f,f), strides=(1,1), padding=\"same\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = bn_relu(X, 3, \"relu\")\n",
        "\n",
        "  #Layer 3\n",
        "  X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "  #Shortcut\n",
        "  X_short = Conv2D(filters=F3, kernel_size=(1,1), strides=(s,s), padding=\"valid\", kernel_initializer = glorot_uniform(seed=0))(x_short_orig)\n",
        "  X_short = BatchNormalization(axis=3)(X_short)\n",
        "\n",
        "  X = Add()([X_short, X])\n",
        "  X = Activation(\"relu\")(X)\n",
        "\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08NrMjm7rfLc"
      },
      "source": [
        "def ResNet50(input_shape, output_classes):\n",
        "\n",
        "  X_input = Input(shape=input_shape)\n",
        "\n",
        "  X = ZeroPadding2D((3,3))(X_input)\n",
        "\n",
        "  #Stage 1\n",
        "  X = Conv2D(filters=64, kernel_size=(7,7), strides=(2,2), kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "  X = BatchNormalization(axis=3)(X)\n",
        "  X = MaxPool2D(pool_size=(3,3), strides=(2,2))(X)\n",
        "\n",
        "  #Stage 2\n",
        "  X = conv_block(X, 3, 1,[64, 64, 256])\n",
        "  X = res_block(X, 3, [64,64,256])\n",
        "  X = res_block(X, 3, [64,64,256])\n",
        "\n",
        "  #Stage 3\n",
        "  X = conv_block(X, 3, 2, [128,128,512])\n",
        "  X = res_block(X, 3, [128,128,512])\n",
        "  X = res_block(X, 3, [128,128,512])\n",
        "  X = res_block(X, 3, [128,128,512])\n",
        "\n",
        "  #Stage 4\n",
        "  X = conv_block(X, 3, 2, [256, 256, 1024])\n",
        "  X = res_block(X, 3, [256,256,1024])\n",
        "  X = res_block(X, 3, [256,256,1024])\n",
        "  X = res_block(X, 3, [256,256,1024])\n",
        "  X = res_block(X, 3, [256,256,1024])\n",
        "  X = res_block(X, 3, [256,256,1024])\n",
        "\n",
        "  #Stage 5\n",
        "  X = conv_block(X, 3, 2, [512,512,2048])\n",
        "  X = res_block(X, 3, [256, 256, 2048])\n",
        "  X = res_block(X, 3, [256, 256, 2048])\n",
        "\n",
        "  X = AveragePooling2D(pool_size=(2,2), padding=\"same\")(X)\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(output_classes, activation=\"softmax\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "\n",
        "  model = Model(inputs=X_input, outputs=X, name=\"ResNet50\")\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udPmHBnCzVWe"
      },
      "source": [
        "model = ResNet50(input_shape=(64,64,3), output_classes=6)\n",
        "model.compile(optimizer=\"adam\", loss=\"CategoricalCrossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm2lrxPPRzff"
      },
      "source": [
        "train_dataset = h5py.File('/content/drive/MyDrive/ML Datasets/finger-signs/Signs_Data_Training.h5', \"r\")\n",
        "train_set_x = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "train_set_y = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "test_dataset = h5py.File('/content/drive/MyDrive/ML Datasets/finger-signs/Signs_Data_Testing.h5', \"r\")\n",
        "test_set_x = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "test_set_y = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "\n",
        "#Converting to 2D Numpy arrays\n",
        "train_set_y = train_set_y.reshape((1, train_set_y.shape[0]))\n",
        "test_set_y = test_set_y.reshape((1, test_set_y.shape[0]))\n",
        "\n",
        "#Converting to One hot arrays\n",
        "Y_test = np.zeros((test_set_y.size, test_set_y.max()+1))\n",
        "Y_test[np.arange(test_set_y.size), test_set_y] = 1\n",
        "\n",
        "Y_train = np.zeros((train_set_y.size, train_set_y.max()+1))\n",
        "Y_train[np.arange(train_set_y.size), train_set_y] = 1\n",
        "\n",
        "X_train = train_set_x / 255\n",
        "X_test = test_set_x / 255\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print(\"number of validation examples = \" + str(X_val.shape[0]))\n",
        "print(\"X_train shape: \" + str(X_train.shape))\n",
        "print(\"Y_train shape: \" + str(Y_train.shape))\n",
        "print(\"X_test shape: \" + str(X_test.shape))\n",
        "print(\"Y_test shape: \" + str(Y_test.shape))\n",
        "print(\"X_val shape: \" + str(X_val.shape))\n",
        "print(\"Y_val shape: \" + str(Y_val.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QPHi-VtaYb4"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=4, validation_data=(X_val, Y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpGMlLVRH958"
      },
      "source": [
        "test = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss = \", str(test[0]))\n",
        "print(\"Accuracy = \", str(test[1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}